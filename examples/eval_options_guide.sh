#!/bin/bash
# Comprehensive guide for evaluation options in the training pipeline

echo "=================================================="
echo "EVALUATION OPTIONS GUIDE"
echo "=================================================="
echo ""
echo "This pipeline provides fine-grained control over evaluation:"
echo "1. --eval_steps: How often to evaluate (in training steps)"
echo "2. --eval_max_batches: How many batches to use per evaluation"
echo ""

echo "=================================================="
echo "1. EVALUATION FREQUENCY (--eval_steps)"
echo "=================================================="
echo ""

echo "# Frequent evaluation (every 50 steps) for close monitoring"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_steps 50"
echo ""

echo "# Standard evaluation (every 500 steps)"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_steps 500"
echo ""

echo "# Infrequent evaluation (every 2000 steps) for long runs"
echo "python train.py --model Qwen/Qwen3-1.7B --dataset openai/gsm8k --dataset_config main \\"
echo "    --eval_steps 2000"
echo ""

echo "=================================================="
echo "2. EVALUATION SCOPE (--eval_max_batches)"
echo "=================================================="
echo ""

echo "# Quick evaluation with only 5 batches (fast but approximate)"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_max_batches 5"
echo ""

echo "# Medium evaluation with 20 batches (balanced)"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_max_batches 20"
echo ""

echo "# Full evaluation (default, use entire validation set)"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_max_batches -1"
echo ""

echo "=================================================="
echo "3. COMBINED STRATEGIES"
echo "=================================================="
echo ""

echo "# Strategy 1: Frequent but quick evaluations"
echo "# Evaluate every 50 steps using only 5 batches"
echo "# Great for early stopping and quick experiments"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_steps 50 --eval_max_batches 5 \\"
echo "    --save_steps 500"
echo ""

echo "# Strategy 2: Balanced evaluation"
echo "# Evaluate every 200 steps using 10 batches"
echo "python train.py --model Qwen/Qwen3-0.6B-Base --dataset glue --dataset_config sst2 \\"
echo "    --eval_steps 200 --eval_max_batches 10 \\"
echo "    --save_steps 1000 --use_lora"
echo ""

echo "# Strategy 3: Production training"
echo "# Infrequent but thorough evaluations"
echo "python train.py --model Qwen/Qwen3-1.7B --dataset virattt/financial-qa-10K \\"
echo "    --eval_steps 1000 --eval_max_batches -1 \\"
echo "    --save_steps 2000"
echo ""

echo "# Strategy 4: Memory-constrained evaluation"
echo "# For large models, limit evaluation batches to save memory"
echo "python train.py --model Qwen/Qwen3-4B-Base --dataset openai/gsm8k --dataset_config main \\"
echo "    --eval_steps 500 --eval_max_batches 3 \\"
echo "    --use_lora --lora_r 16 --batch_size 2"
echo ""

echo "=================================================="
echo "4. USE CASES AND RECOMMENDATIONS"
echo "=================================================="
echo ""

echo "QUICK EXPERIMENTS:"
echo "  --eval_steps 25-50"
echo "  --eval_max_batches 3-5"
echo "  Purpose: Fast feedback during development"
echo ""

echo "HYPERPARAMETER TUNING:"
echo "  --eval_steps 100-200"
echo "  --eval_max_batches 10-20"
echo "  Purpose: Balance between accuracy and speed"
echo ""

echo "EARLY STOPPING:"
echo "  --eval_steps 50-100"
echo "  --eval_max_batches 10-20"
echo "  --load_best_model_at_end"
echo "  Purpose: Detect overfitting quickly"
echo ""

echo "PRODUCTION TRAINING:"
echo "  --eval_steps 500-2000"
echo "  --eval_max_batches -1 (full evaluation)"
echo "  Purpose: Accurate metrics, less overhead"
echo ""

echo "LARGE MODEL TRAINING:"
echo "  --eval_steps 1000+"
echo "  --eval_max_batches 5-10"
echo "  Purpose: Reduce memory usage and time"
echo ""

echo "=================================================="
echo "5. ADVANCED EXAMPLES"
echo "=================================================="
echo ""

echo "# Example: Early stopping with limited evaluation"
echo "python train.py --model gpt2 --dataset stanfordnlp/imdb --mode sft \\"
echo "    --eval_steps 100 --eval_max_batches 10 \\"
echo "    --save_steps 500 --save_total_limit 3 \\"
echo "    --load_best_model_at_end --metric_for_best_model eval_loss \\"
echo "    --early_stopping_patience 5"
echo ""

echo "# Example: Multi-dataset training with efficient evaluation"
echo "python train.py --model gpt2 \\"
echo "    --datasets stanfordnlp/imdb glue \\"
echo "    --dataset_configs None sst2 \\"
echo "    --mixture_rates 0.6 0.4 \\"
echo "    --mode sft \\"
echo "    --eval_steps 200 --eval_max_batches 15"
echo ""

echo "# Example: LoRA fine-tuning with memory-efficient evaluation"
echo "python train.py --model Qwen/Qwen3-4B-Base --dataset virattt/financial-qa-10K \\"
echo "    --mode sft --use_lora --lora_r 32 --lora_alpha 64 \\"
echo "    --batch_size 2 --gradient_accumulation_steps 8 \\"
echo "    --eval_steps 100 --eval_max_batches 5"
echo ""

echo "=================================================="
echo "NOTES:"
echo "- eval_max_batches=-1 means use the entire validation set"
echo "- Smaller eval_max_batches values give faster but less accurate metrics"
echo "- Combine with eval_steps for optimal training monitoring"
echo "- These options are especially useful for large models and datasets"
echo "=================================================="