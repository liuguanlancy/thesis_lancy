\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Questions}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions}{3}{section.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Thesis Organization}{5}{section.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Scope and Limitations}{6}{section.1.5}\protected@file@percent }
\abx@aux@cite{chen2023finbert}
\abx@aux@segm{0}{0}{chen2023finbert}
\abx@aux@cite{yang2020finqa}
\abx@aux@segm{0}{0}{yang2020finqa}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{yang2020finbert}
\abx@aux@segm{0}{0}{yang2020finbert}
\abx@aux@cite{yang2023fingpt}
\abx@aux@segm{0}{0}{yang2023fingpt}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Related Work}{8}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Financial NLP}{8}{section.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The Financial NLP Landscape}{8}{subsection.2.1.1}\protected@file@percent }
\abx@aux@page{1}{8}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{radford2019language}
\abx@aux@segm{0}{0}{radford2019language}
\abx@aux@cite{brown2020language}
\abx@aux@segm{0}{0}{brown2020language}
\abx@aux@cite{vaswani2017attention}
\abx@aux@segm{0}{0}{vaswani2017attention}
\abx@aux@cite{touvron2023llama}
\abx@aux@segm{0}{0}{touvron2023llama}
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\abx@aux@cite{tay2022ul2}
\abx@aux@segm{0}{0}{tay2022ul2}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Existing Financial Language Models}{9}{subsection.2.1.2}\protected@file@percent }
\abx@aux@page{2}{9}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Domain-Specific Challenges}{9}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Language Model Pretraining}{9}{section.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Pretraining Objectives and Architecture}{9}{subsection.2.2.1}\protected@file@percent }
\abx@aux@page{3}{9}
\abx@aux@page{4}{9}
\abx@aux@page{5}{9}
\abx@aux@cite{mccandlish2018empirical}
\abx@aux@segm{0}{0}{mccandlish2018empirical}
\abx@aux@cite{rajbhandari2020zero}
\abx@aux@segm{0}{0}{rajbhandari2020zero}
\abx@aux@cite{narayanan2021efficient}
\abx@aux@segm{0}{0}{narayanan2021efficient}
\abx@aux@cite{bengio2009curriculum}
\abx@aux@segm{0}{0}{bengio2009curriculum}
\abx@aux@cite{wu2022opt}
\abx@aux@segm{0}{0}{wu2022opt}
\abx@aux@cite{washington2020curriculum}
\abx@aux@segm{0}{0}{washington2020curriculum}
\abx@aux@cite{xu2020curriculum}
\abx@aux@segm{0}{0}{xu2020curriculum}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Scaling Laws and Model Size Effects}{10}{subsection.2.2.2}\protected@file@percent }
\abx@aux@page{6}{10}
\abx@aux@page{7}{10}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Computational and Memory Considerations}{10}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Data Mixture Strategies}{10}{section.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Curriculum Learning and Sequential Mixing}{10}{subsection.2.3.1}\protected@file@percent }
\abx@aux@cite{raffel2020exploring}
\abx@aux@segm{0}{0}{raffel2020exploring}
\abx@aux@cite{xie2023doremi}
\abx@aux@segm{0}{0}{xie2023doremi}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{arivazhagan2019massively}
\abx@aux@segm{0}{0}{arivazhagan2019massively}
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\abx@aux@cite{sanh2022multitask}
\abx@aux@segm{0}{0}{sanh2022multitask}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Simultaneous Mixture Approaches}{11}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Domain Proportions and Sampling Strategies}{11}{subsection.2.3.3}\protected@file@percent }
\abx@aux@cite{devlin2019bert}
\abx@aux@segm{0}{0}{devlin2019bert}
\abx@aux@cite{gururangan2020don}
\abx@aux@segm{0}{0}{gururangan2020don}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{yang2020finbert}
\abx@aux@segm{0}{0}{yang2020finbert}
\abx@aux@cite{mccloskey1989catastrophic}
\abx@aux@segm{0}{0}{mccloskey1989catastrophic}
\abx@aux@cite{french1999catastrophic}
\abx@aux@segm{0}{0}{french1999catastrophic}
\abx@aux@cite{kirkpatrick2017overcoming}
\abx@aux@segm{0}{0}{kirkpatrick2017overcoming}
\abx@aux@cite{lee2022surgical}
\abx@aux@segm{0}{0}{lee2022surgical}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Domain Adaptation and Transfer Learning}{12}{section.2.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Cross-Domain Transfer in Language Models}{12}{subsection.2.4.1}\protected@file@percent }
\abx@aux@page{8}{12}
\abx@aux@page{9}{12}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Catastrophic Forgetting and Stability}{12}{subsection.2.4.2}\protected@file@percent }
\abx@aux@cite{quinonero2009dataset}
\abx@aux@segm{0}{0}{quinonero2009dataset}
\abx@aux@cite{aharoni2020unsupervised}
\abx@aux@segm{0}{0}{aharoni2020unsupervised}
\abx@aux@cite{xie2023doremi}
\abx@aux@segm{0}{0}{xie2023doremi}
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\abx@aux@cite{hoffman2024training}
\abx@aux@segm{0}{0}{hoffman2024training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Distribution Shift and Domain Mismatch}{13}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Related Empirical Studies}{13}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{14}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimental Design Overview}{14}{section.3.1}\protected@file@percent }
\abx@aux@cite{yang2024qwen3}
\abx@aux@segm{0}{0}{yang2024qwen3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Model Architecture}{15}{section.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Datasets}{16}{section.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Financial Datasets}{16}{subsection.3.3.1}\protected@file@percent }
\abx@aux@cite{merity2017pointer}
\abx@aux@segm{0}{0}{merity2017pointer}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}WikiText}{17}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Mixture Strategies}{17}{subsection.3.3.3}\protected@file@percent }
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training Setup and Hyperparameter Tuning}{18}{section.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Initial Configuration}{18}{subsection.3.4.1}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Discovery of Reverse Scaling}{19}{subsection.3.4.2}\protected@file@percent }
\abx@aux@page{10}{19}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Systematic Learning Rate Adjustment}{19}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Final Learning Rate Recommendations}{20}{subsection.3.4.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Learning rate recommendations by model size. Reduction factors follow approximate inverse square-root scaling relative to 0.6B baseline.\relax }}{20}{table.caption.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Other Hyperparameters}{21}{subsection.3.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Evaluation Protocol}{21}{section.3.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Multi-Dataset Evaluation}{21}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Metrics}{22}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{23}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Overview of Experimental Results}{23}{section.4.1}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Overview of 10 pretraining experiments. Perplexity reported for best-performing model size on the corresponding training dataset's test set. Epochs vary by model size to normalize token exposure ($\sim $100M tokens per model).\relax }}{23}{table.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:experiments_overview}{{4.1}{23}{Overview of 10 pretraining experiments. Perplexity reported for best-performing model size on the corresponding training dataset's test set. Epochs vary by model size to normalize token exposure ($\sim $100M tokens per model).\relax }{table.caption.7}{}}
\newlabel{tab:experiments_overview@cref}{{[table][1][4]4.1}{[1][23][]23}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data Mixture Effects: The Core Finding}{24}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Mixed Financial Datasets}{24}{subsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Mixed Financial Dataset: Model scaling behavior across 0.6B, 1.7B, and 4B parameters. Left panel shows perplexity (log scale) decreasing consistently with model size. Right panel shows cross-entropy loss following expected scaling pattern. Both metrics demonstrate normal scaling with 22.6\% total improvement from 0.6B to 4B.\relax }}{25}{figure.caption.8}\protected@file@percent }
\newlabel{fig:scaling_mixed_financial}{{4.1}{25}{Mixed Financial Dataset: Model scaling behavior across 0.6B, 1.7B, and 4B parameters. Left panel shows perplexity (log scale) decreasing consistently with model size. Right panel shows cross-entropy loss following expected scaling pattern. Both metrics demonstrate normal scaling with 22.6\% total improvement from 0.6B to 4B.\relax }{figure.caption.8}{}}
\newlabel{fig:scaling_mixed_financial@cref}{{[figure][1][4]4.1}{[1][25][]25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Mixed Wiki+Financial}{25}{subsection.4.2.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Mixed Financial Dataset: Evaluation Across Multiple Datasets\relax }}{26}{table.caption.9}\protected@file@percent }
\newlabel{tab:mixed_financial_results}{{4.2}{26}{Mixed Financial Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.9}{}}
\newlabel{tab:mixed_financial_results@cref}{{[table][2][4]4.2}{[1][25][]26}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Mixed Wiki+Financial Dataset: Scaling behavior shows normal pattern but with higher perplexity than pure financial mixture. The 15.1\% total improvement (0.6B to 4B) is smaller than pure financial (22.6\%), suggesting domain mixture creates competing optimization pressures that limit scaling benefits.\relax }}{27}{figure.caption.10}\protected@file@percent }
\newlabel{fig:scaling_mixed_wiki_financial}{{4.2}{27}{Mixed Wiki+Financial Dataset: Scaling behavior shows normal pattern but with higher perplexity than pure financial mixture. The 15.1\% total improvement (0.6B to 4B) is smaller than pure financial (22.6\%), suggesting domain mixture creates competing optimization pressures that limit scaling benefits.\relax }{figure.caption.10}{}}
\newlabel{fig:scaling_mixed_wiki_financial@cref}{{[figure][2][4]4.2}{[1][26][]27}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Pure WikiText Baseline}{27}{subsection.4.2.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Mixed Wiki+Financial Dataset: Evaluation Across Multiple Datasets\relax }}{28}{table.caption.11}\protected@file@percent }
\newlabel{tab:mixed_wiki_financial_results}{{4.3}{28}{Mixed Wiki+Financial Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.11}{}}
\newlabel{tab:mixed_wiki_financial_results@cref}{{[table][3][4]4.3}{[1][26][]28}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Key Takeaway}{28}{subsection.4.2.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces WikiText Dataset: Severe reverse scaling phenomenon. The 1.7B model shows adjusted learning rate results (dashed line, squares) after fixing training collapse. The 4B model required 75\% LR reduction to stabilize. Clean, structured data amplifies learning rate sensitivity at larger scales.\relax }}{29}{figure.caption.12}\protected@file@percent }
\newlabel{fig:scaling_wikitext}{{4.3}{29}{WikiText Dataset: Severe reverse scaling phenomenon. The 1.7B model shows adjusted learning rate results (dashed line, squares) after fixing training collapse. The 4B model required 75\% LR reduction to stabilize. Clean, structured data amplifies learning rate sensitivity at larger scales.\relax }{figure.caption.12}{}}
\newlabel{fig:scaling_wikitext@cref}{{[figure][3][4]4.3}{[1][28][]29}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces WikiText Dataset: Impact of Learning Rate Adjustments\relax }}{29}{table.caption.13}\protected@file@percent }
\newlabel{tab:wikitext_lr_comparison}{{4.4}{29}{WikiText Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.13}{}}
\newlabel{tab:wikitext_lr_comparison@cref}{{[table][4][4]4.4}{[1][28][]29}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Comparison of all three mixture strategies across model sizes. Mixed Financial (blue) consistently outperforms Mixed Wiki+Financial (orange) and WikiText (green) on financial evaluation metrics. The divergence increases with model size, demonstrating that in-domain diversity scales better than general-domain quality.\relax }}{30}{figure.caption.14}\protected@file@percent }
\newlabel{fig:scaling_comparison_all}{{4.4}{30}{Comparison of all three mixture strategies across model sizes. Mixed Financial (blue) consistently outperforms Mixed Wiki+Financial (orange) and WikiText (green) on financial evaluation metrics. The divergence increases with model size, demonstrating that in-domain diversity scales better than general-domain quality.\relax }{figure.caption.14}{}}
\newlabel{fig:scaling_comparison_all@cref}{{[figure][4][4]4.4}{[1][30][]30}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Individual Dataset Analysis: Component Effects}{30}{section.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Large Datasets}{30}{subsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Financial News Articles Dataset: Excellent normal scaling with 21.7\% total improvement (0.6B to 4B). Large dataset size (197M tokens) provides sufficient diversity for stable training across all model sizes with minimal overtraining (2-3 epochs).\relax }}{32}{figure.caption.15}\protected@file@percent }
\newlabel{fig:scaling_news_articles}{{4.5}{32}{Financial News Articles Dataset: Excellent normal scaling with 21.7\% total improvement (0.6B to 4B). Large dataset size (197M tokens) provides sufficient diversity for stable training across all model sizes with minimal overtraining (2-3 epochs).\relax }{figure.caption.15}{}}
\newlabel{fig:scaling_news_articles@cref}{{[figure][5][4]4.5}{[1][31][]32}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces SEC Reports Dataset: Consistent normal scaling with 22.4\% total improvement. The 80M token corpus supports standalone pretraining with moderate overtraining (6-24 epochs). Strong transfer to similar long-form documents.\relax }}{32}{figure.caption.16}\protected@file@percent }
\newlabel{fig:scaling_sec_reports}{{4.6}{32}{SEC Reports Dataset: Consistent normal scaling with 22.4\% total improvement. The 80M token corpus supports standalone pretraining with moderate overtraining (6-24 epochs). Strong transfer to similar long-form documents.\relax }{figure.caption.16}{}}
\newlabel{fig:scaling_sec_reports@cref}{{[figure][6][4]4.6}{[1][31][]32}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Medium Datasets}{32}{subsection.4.3.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Financial News Dataset: Evaluation Across Multiple Datasets\relax }}{33}{table.caption.17}\protected@file@percent }
\newlabel{tab:news_articles_results}{{4.5}{33}{Financial News Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.17}{}}
\newlabel{tab:news_articles_results@cref}{{[table][5][4]4.5}{[1][31][]33}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces SEC Reports Dataset: Evaluation Across Multiple Datasets\relax }}{34}{table.caption.18}\protected@file@percent }
\newlabel{tab:sec_reports_results}{{4.6}{34}{SEC Reports Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.18}{}}
\newlabel{tab:sec_reports_results@cref}{{[table][6][4]4.6}{[1][31][]34}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Small Datasets}{34}{subsection.4.3.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces FinGPT Sentiment Dataset: Normal scaling with 22.1\% improvement despite moderate overtraining (12-30 epochs). Instruction-following format benefits from increased model capacity, showing strong transfer to similar task types.\relax }}{35}{figure.caption.19}\protected@file@percent }
\newlabel{fig:scaling_fingpt}{{4.7}{35}{FinGPT Sentiment Dataset: Normal scaling with 22.1\% improvement despite moderate overtraining (12-30 epochs). Instruction-following format benefits from increased model capacity, showing strong transfer to similar task types.\relax }{figure.caption.19}{}}
\newlabel{fig:scaling_fingpt@cref}{{[figure][7][4]4.7}{[1][34][]35}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Finance Alpaca Dataset: Consistent 21.8\% improvement across model sizes. Educational Q\&A format shows reliable scaling despite 13-25 epochs of training, but exhibits narrow task focus with 48\% cross-dataset variance.\relax }}{35}{figure.caption.20}\protected@file@percent }
\newlabel{fig:scaling_alpaca}{{4.8}{35}{Finance Alpaca Dataset: Consistent 21.8\% improvement across model sizes. Educational Q\&A format shows reliable scaling despite 13-25 epochs of training, but exhibits narrow task focus with 48\% cross-dataset variance.\relax }{figure.caption.20}{}}
\newlabel{fig:scaling_alpaca@cref}{{[figure][8][4]4.8}{[1][34][]35}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces FiQA Dataset: Strong normal scaling with 25.2\% total improvement. Despite small size (4M tokens), conversational Q\&A format produces stable training and excellent in-domain performance, though with high variance (52\%) on out-of-format tasks.\relax }}{36}{figure.caption.21}\protected@file@percent }
\newlabel{fig:scaling_fiqa}{{4.9}{36}{FiQA Dataset: Strong normal scaling with 25.2\% total improvement. Despite small size (4M tokens), conversational Q\&A format produces stable training and excellent in-domain performance, though with high variance (52\%) on out-of-format tasks.\relax }{figure.caption.21}{}}
\newlabel{fig:scaling_fiqa@cref}{{[figure][9][4]4.9}{[1][34][]36}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces FinGPT Sentiment Dataset: Evaluation Across Multiple Datasets\relax }}{37}{table.caption.22}\protected@file@percent }
\newlabel{tab:fingpt_results}{{4.7}{37}{FinGPT Sentiment Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.22}{}}
\newlabel{tab:fingpt_results@cref}{{[table][7][4]4.7}{[1][34][]37}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Financial QA 10K Dataset: Moderate reverse scaling resolved via learning rate adjustment. The 4B model (dashed line, squares) shows adjusted LR results with 10.3\% improvement, recovering expected scaling order. Extreme overtraining (67-100 epochs) causes 89\% cross-dataset variance.\relax }}{37}{figure.caption.25}\protected@file@percent }
\newlabel{fig:scaling_financial_qa}{{4.10}{37}{Financial QA 10K Dataset: Moderate reverse scaling resolved via learning rate adjustment. The 4B model (dashed line, squares) shows adjusted LR results with 10.3\% improvement, recovering expected scaling order. Extreme overtraining (67-100 epochs) causes 89\% cross-dataset variance.\relax }{figure.caption.25}{}}
\newlabel{fig:scaling_financial_qa@cref}{{[figure][10][4]4.10}{[1][37][]37}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Dataset Size vs Generalization}{37}{subsection.4.3.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Finance Alpaca Dataset: Evaluation Across Multiple Datasets\relax }}{38}{table.caption.23}\protected@file@percent }
\newlabel{tab:alpaca_results}{{4.8}{38}{Finance Alpaca Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.23}{}}
\newlabel{tab:alpaca_results@cref}{{[table][8][4]4.8}{[1][34][]38}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces FiQA Dataset: Evaluation Across Multiple Datasets\relax }}{39}{table.caption.24}\protected@file@percent }
\newlabel{tab:fiqa_results}{{4.9}{39}{FiQA Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.24}{}}
\newlabel{tab:fiqa_results@cref}{{[table][9][4]4.9}{[1][34][]39}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Financial QA 10K Dataset: Impact of Learning Rate Adjustments\relax }}{39}{table.caption.27}\protected@file@percent }
\newlabel{tab:financial_qa_lr_comparison}{{4.10}{39}{Financial QA 10K Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.27}{}}
\newlabel{tab:financial_qa_lr_comparison@cref}{{[table][10][4]4.10}{[1][37][]39}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Training Dynamics and Scaling Behavior}{39}{section.4.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Twitter Financial Sentiment Dataset: Severe reverse scaling phenomenon. The 4B model (dashed line, squares) required 75\% LR reduction to recover performance, achieving 31.6\% improvement. Extremely small dataset (0.3M tokens, 150-249 epochs) creates brittle optimization landscape with 89\% variance.\relax }}{40}{figure.caption.26}\protected@file@percent }
\newlabel{fig:scaling_twitter}{{4.11}{40}{Twitter Financial Sentiment Dataset: Severe reverse scaling phenomenon. The 4B model (dashed line, squares) required 75\% LR reduction to recover performance, achieving 31.6\% improvement. Extremely small dataset (0.3M tokens, 150-249 epochs) creates brittle optimization landscape with 89\% variance.\relax }{figure.caption.26}{}}
\newlabel{fig:scaling_twitter@cref}{{[figure][11][4]4.11}{[1][37][]40}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Twitter Financial Dataset: Impact of Learning Rate Adjustments\relax }}{40}{table.caption.28}\protected@file@percent }
\newlabel{tab:twitter_lr_comparison}{{4.11}{40}{Twitter Financial Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.28}{}}
\newlabel{tab:twitter_lr_comparison@cref}{{[table][11][4]4.11}{[1][37][]40}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Normal Scaling Pattern}{40}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Reverse Scaling Phenomenon}{41}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Learning Rate Sensitivity by Model Size}{43}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Fixing Reverse Scaling}{44}{subsection.4.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Model Stability Analysis}{46}{subsection.4.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Domain Transfer and Generalization Patterns}{47}{section.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Cross-Dataset Evaluation}{47}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Document Format and Task Type Effects}{49}{subsection.4.5.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Financial News Evaluation: Performance Across Training Datasets\relax }}{49}{table.caption.29}\protected@file@percent }
\newlabel{tab:cross_financial_news}{{4.12}{49}{Financial News Evaluation: Performance Across Training Datasets\relax }{table.caption.29}{}}
\newlabel{tab:cross_financial_news@cref}{{[table][12][4]4.12}{[1][49][]49}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces SEC Reports Evaluation: Performance Across Training Datasets\relax }}{50}{table.caption.30}\protected@file@percent }
\newlabel{tab:cross_financial_repor}{{4.13}{50}{SEC Reports Evaluation: Performance Across Training Datasets\relax }{table.caption.30}{}}
\newlabel{tab:cross_financial_repor@cref}{{[table][13][4]4.13}{[1][49][]50}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Alpaca Evaluation: Performance Across Training Datasets\relax }}{51}{table.caption.31}\protected@file@percent }
\newlabel{tab:cross_alpaca}{{4.14}{51}{Alpaca Evaluation: Performance Across Training Datasets\relax }{table.caption.31}{}}
\newlabel{tab:cross_alpaca@cref}{{[table][14][4]4.14}{[1][50][]51}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.15}{\ignorespaces FinGPT Evaluation: Performance Across Training Datasets\relax }}{52}{table.caption.32}\protected@file@percent }
\newlabel{tab:cross_fingpt}{{4.15}{52}{FinGPT Evaluation: Performance Across Training Datasets\relax }{table.caption.32}{}}
\newlabel{tab:cross_fingpt@cref}{{[table][15][4]4.15}{[1][50][]52}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Variance Comparison}{52}{subsection.4.5.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.16}{\ignorespaces FiQA Evaluation: Performance Across Training Datasets\relax }}{53}{table.caption.33}\protected@file@percent }
\newlabel{tab:cross_fiqa}{{4.16}{53}{FiQA Evaluation: Performance Across Training Datasets\relax }{table.caption.33}{}}
\newlabel{tab:cross_fiqa@cref}{{[table][16][4]4.16}{[1][50][]53}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.17}{\ignorespaces Twitter Financial Evaluation: Performance Across Training Datasets\relax }}{54}{table.caption.34}\protected@file@percent }
\newlabel{tab:cross_twitter}{{4.17}{54}{Twitter Financial Evaluation: Performance Across Training Datasets\relax }{table.caption.34}{}}
\newlabel{tab:cross_twitter@cref}{{[table][17][4]4.17}{[1][51][]54}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.18}{\ignorespaces Financial QA Evaluation: Performance Across Training Datasets\relax }}{55}{table.caption.35}\protected@file@percent }
\newlabel{tab:cross_financial_qa}{{4.18}{55}{Financial QA Evaluation: Performance Across Training Datasets\relax }{table.caption.35}{}}
\newlabel{tab:cross_financial_qa@cref}{{[table][18][4]4.18}{[1][54][]55}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Domain-Specific vs General Knowledge Transfer}{55}{subsection.4.5.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.19}{\ignorespaces WikiText Evaluation: Performance Across Training Datasets\relax }}{57}{table.caption.36}\protected@file@percent }
\newlabel{tab:cross_wikitext}{{4.19}{57}{WikiText Evaluation: Performance Across Training Datasets\relax }{table.caption.36}{}}
\newlabel{tab:cross_wikitext@cref}{{[table][19][4]4.19}{[1][57][]57}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Summary and Key Results}{58}{section.4.6}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.20}{\ignorespaces Best configurations by application. *SEC's 18\% CV is in-domain only; cross-dataset CV is 32\%.\relax }}{59}{table.caption.37}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{61}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Key Empirical Findings}{61}{section.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Interpretation of Data Interaction Effects}{63}{section.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Why WikiText Underperforms on Financial Tasks}{63}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Benefits of In-Domain Diversity}{64}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Domain Interference Patterns}{66}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Scale-Dependent Training Dynamics}{67}{subsection.5.2.4}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\abx@aux@page{11}{68}
\abx@aux@page{12}{68}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Practical Guidelines for Financial LM Pretraining}{68}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Data Mixture Strategies by Use Case}{68}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Model Size Selection}{69}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Learning Rate Guidelines by Model Size}{70}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Token Budget Allocation}{71}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Limitations and Threats to Validity}{71}{section.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{73}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary of Contributions}{73}{section.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Data Mixture Guidelines for Financial NLP}{73}{subsection.6.1.1}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Learning Rate Scaling Laws for Decoder-Only Transformers}{74}{subsection.6.1.2}\protected@file@percent }
\abx@aux@page{13}{74}
\abx@aux@page{14}{74}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Dataset Size Effects and Generalization}{75}{subsection.6.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Domain Transfer and Format Effects}{75}{subsection.6.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.5}Model Size Selection for Resource-Constrained Settings}{76}{subsection.6.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.6}Open-Source Reproducible Pipeline}{77}{subsection.6.1.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}Implications for Practice and Research}{77}{section.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}For Practitioners: Actionable Deployment Guidelines}{77}{subsection.6.2.1}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}For Researchers: Open Questions and Methodological Lessons}{78}{subsection.6.2.2}\protected@file@percent }
\abx@aux@page{15}{78}
\abx@aux@page{16}{78}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}For Industry: Privacy-Preserving Financial AI}{79}{subsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future Research Directions}{79}{section.6.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Scaling to Larger Models and Architectures}{79}{subsection.6.3.1}\protected@file@percent }
\abx@aux@cite{doremi2023}
\abx@aux@segm{0}{0}{doremi2023}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Advanced Mixture Optimization}{80}{subsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Comprehensive Downstream Evaluation}{81}{subsection.6.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Multi-Stage Pretraining Strategies}{81}{subsection.6.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}Theoretical Understanding of Learning Rate Scaling}{82}{subsection.6.3.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.4}Closing Remarks}{83}{section.6.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Appendices}{}{section*.38}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Experimental Details}{85}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chp:experimental_details}{{A}{85}{Experimental Details}{appendix.A}{}}
\newlabel{chp:experimental_details@cref}{{[appendix][1][2147483647]A}{[1][85][]85}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.1}Complete Hyperparameter Tables}{85}{section.A.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.2}Additional Results Tables}{85}{section.A.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.3}Dataset Preprocessing Details}{85}{section.A.3}\protected@file@percent }
\abx@aux@page{17}{86}
\abx@aux@page{18}{86}
\abx@aux@page{19}{86}
\abx@aux@page{20}{86}
\abx@aux@page{21}{86}
\abx@aux@page{22}{86}
\abx@aux@page{23}{86}
\abx@aux@read@bbl@mdfivesum{55A51D7A69101CFBDBC3B10BB8907F8E}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{araci2019finbert}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{brown2020language}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{gururangan2020don}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hoffmann2022training}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kaplan2020scaling}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{radford2019language}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{touvron2023llama}{nyt/global//global/global}
\gdef \@abspage@last{99}
