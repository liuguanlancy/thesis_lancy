\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{nyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Questions}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Contributions}{3}{section.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Thesis Organization}{5}{section.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Scope and Limitations}{5}{section.1.5}\protected@file@percent }
\abx@aux@cite{chen2023finbert}
\abx@aux@segm{0}{0}{chen2023finbert}
\abx@aux@cite{yang2020finqa}
\abx@aux@segm{0}{0}{yang2020finqa}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{yang2020finbert}
\abx@aux@segm{0}{0}{yang2020finbert}
\abx@aux@cite{yang2023fingpt}
\abx@aux@segm{0}{0}{yang2023fingpt}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Related Work}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Financial NLP}{7}{section.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The Financial NLP Landscape}{7}{subsection.2.1.1}\protected@file@percent }
\abx@aux@page{1}{7}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{radford2019language}
\abx@aux@segm{0}{0}{radford2019language}
\abx@aux@cite{brown2020language}
\abx@aux@segm{0}{0}{brown2020language}
\abx@aux@cite{vaswani2017attention}
\abx@aux@segm{0}{0}{vaswani2017attention}
\abx@aux@cite{touvron2023llama}
\abx@aux@segm{0}{0}{touvron2023llama}
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\abx@aux@cite{tay2022ul2}
\abx@aux@segm{0}{0}{tay2022ul2}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Existing Financial Language Models}{8}{subsection.2.1.2}\protected@file@percent }
\abx@aux@page{2}{8}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Domain-Specific Challenges}{8}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Language Model Pretraining}{8}{section.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Pretraining Objectives and Architecture}{8}{subsection.2.2.1}\protected@file@percent }
\abx@aux@page{3}{8}
\abx@aux@page{4}{8}
\abx@aux@page{5}{8}
\abx@aux@cite{mccandlish2018empirical}
\abx@aux@segm{0}{0}{mccandlish2018empirical}
\abx@aux@cite{rajbhandari2020zero}
\abx@aux@segm{0}{0}{rajbhandari2020zero}
\abx@aux@cite{narayanan2021efficient}
\abx@aux@segm{0}{0}{narayanan2021efficient}
\abx@aux@cite{bengio2009curriculum}
\abx@aux@segm{0}{0}{bengio2009curriculum}
\abx@aux@cite{wu2022opt}
\abx@aux@segm{0}{0}{wu2022opt}
\abx@aux@cite{washington2020curriculum}
\abx@aux@segm{0}{0}{washington2020curriculum}
\abx@aux@cite{xu2020curriculum}
\abx@aux@segm{0}{0}{xu2020curriculum}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Scaling Laws and Model Size Effects}{9}{subsection.2.2.2}\protected@file@percent }
\abx@aux@page{6}{9}
\abx@aux@page{7}{9}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Computational and Memory Considerations}{9}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Data Mixture Strategies}{9}{section.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Curriculum Learning and Sequential Mixing}{9}{subsection.2.3.1}\protected@file@percent }
\abx@aux@cite{raffel2020exploring}
\abx@aux@segm{0}{0}{raffel2020exploring}
\abx@aux@cite{xie2023doremi}
\abx@aux@segm{0}{0}{xie2023doremi}
\abx@aux@cite{wu2023bloomberggpt}
\abx@aux@segm{0}{0}{wu2023bloomberggpt}
\abx@aux@cite{arivazhagan2019massively}
\abx@aux@segm{0}{0}{arivazhagan2019massively}
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\abx@aux@cite{sanh2022multitask}
\abx@aux@segm{0}{0}{sanh2022multitask}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Simultaneous Mixture Approaches}{10}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Domain Proportions and Sampling Strategies}{10}{subsection.2.3.3}\protected@file@percent }
\abx@aux@cite{devlin2019bert}
\abx@aux@segm{0}{0}{devlin2019bert}
\abx@aux@cite{gururangan2020don}
\abx@aux@segm{0}{0}{gururangan2020don}
\abx@aux@cite{araci2019finbert}
\abx@aux@segm{0}{0}{araci2019finbert}
\abx@aux@cite{yang2020finbert}
\abx@aux@segm{0}{0}{yang2020finbert}
\abx@aux@cite{mccloskey1989catastrophic}
\abx@aux@segm{0}{0}{mccloskey1989catastrophic}
\abx@aux@cite{french1999catastrophic}
\abx@aux@segm{0}{0}{french1999catastrophic}
\abx@aux@cite{kirkpatrick2017overcoming}
\abx@aux@segm{0}{0}{kirkpatrick2017overcoming}
\abx@aux@cite{lee2022surgical}
\abx@aux@segm{0}{0}{lee2022surgical}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Domain Adaptation and Transfer Learning}{11}{section.2.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Cross-Domain Transfer in Language Models}{11}{subsection.2.4.1}\protected@file@percent }
\abx@aux@page{8}{11}
\abx@aux@page{9}{11}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Catastrophic Forgetting and Stability}{11}{subsection.2.4.2}\protected@file@percent }
\abx@aux@cite{quinonero2009dataset}
\abx@aux@segm{0}{0}{quinonero2009dataset}
\abx@aux@cite{aharoni2020unsupervised}
\abx@aux@segm{0}{0}{aharoni2020unsupervised}
\abx@aux@cite{xie2023doremi}
\abx@aux@segm{0}{0}{xie2023doremi}
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\abx@aux@cite{hoffman2024training}
\abx@aux@segm{0}{0}{hoffman2024training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Distribution Shift and Domain Mismatch}{12}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Related Empirical Studies}{12}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{13}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimental Design Overview}{13}{section.3.1}\protected@file@percent }
\abx@aux@cite{yang2024qwen3}
\abx@aux@segm{0}{0}{yang2024qwen3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Model Architecture}{14}{section.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Datasets}{15}{section.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Financial Datasets}{15}{subsection.3.3.1}\protected@file@percent }
\abx@aux@cite{merity2017pointer}
\abx@aux@segm{0}{0}{merity2017pointer}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}WikiText}{16}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Mixture Strategies}{16}{subsection.3.3.3}\protected@file@percent }
\abx@aux@cite{longpre2023pretrainer}
\abx@aux@segm{0}{0}{longpre2023pretrainer}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training Setup and Hyperparameter Tuning}{17}{section.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Initial Configuration}{17}{subsection.3.4.1}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Discovery of Reverse Scaling}{18}{subsection.3.4.2}\protected@file@percent }
\abx@aux@page{10}{18}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Systematic Learning Rate Adjustment}{18}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Final Learning Rate Recommendations}{19}{subsection.3.4.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Learning rate recommendations by model size. Reduction factors follow approximate inverse square-root scaling relative to 0.6B baseline.\relax }}{19}{table.caption.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Other Hyperparameters}{20}{subsection.3.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Evaluation Protocol}{20}{section.3.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Multi-Dataset Evaluation}{20}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Metrics}{21}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{22}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Overview of Experimental Results}{22}{section.4.1}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Overview of 10 pretraining experiments. Perplexity reported for best-performing model size on the corresponding training dataset's test set. Epochs vary by model size to normalize token exposure ($\sim $100M tokens per model).\relax }}{22}{table.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:experiments_overview}{{4.1}{22}{Overview of 10 pretraining experiments. Perplexity reported for best-performing model size on the corresponding training dataset's test set. Epochs vary by model size to normalize token exposure ($\sim $100M tokens per model).\relax }{table.caption.7}{}}
\newlabel{tab:experiments_overview@cref}{{[table][1][4]4.1}{[1][22][]22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data Mixture Effects: The Core Finding}{23}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Mixed Financial Datasets}{23}{subsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Mixed Financial Dataset: Model scaling behavior across 0.6B, 1.7B, and 4B parameters. Left panel shows perplexity (log scale) decreasing consistently with model size. Right panel shows cross-entropy loss following expected scaling pattern. Both metrics demonstrate normal scaling with 22.6\% total improvement from 0.6B to 4B.\relax }}{24}{figure.caption.8}\protected@file@percent }
\newlabel{fig:scaling_mixed_financial}{{4.1}{24}{Mixed Financial Dataset: Model scaling behavior across 0.6B, 1.7B, and 4B parameters. Left panel shows perplexity (log scale) decreasing consistently with model size. Right panel shows cross-entropy loss following expected scaling pattern. Both metrics demonstrate normal scaling with 22.6\% total improvement from 0.6B to 4B.\relax }{figure.caption.8}{}}
\newlabel{fig:scaling_mixed_financial@cref}{{[figure][1][4]4.1}{[1][24][]24}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Mixed Wiki+Financial}{24}{subsection.4.2.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Mixed Financial Dataset: Evaluation Across Multiple Datasets\relax }}{25}{table.caption.9}\protected@file@percent }
\newlabel{tab:mixed_financial_results}{{4.2}{25}{Mixed Financial Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.9}{}}
\newlabel{tab:mixed_financial_results@cref}{{[table][2][4]4.2}{[1][24][]25}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Mixed Wiki+Financial Dataset: Scaling behavior shows normal pattern but with higher perplexity than pure financial mixture. The 15.1\% total improvement (0.6B to 4B) is smaller than pure financial (22.6\%), suggesting domain mixture creates competing optimization pressures that limit scaling benefits.\relax }}{26}{figure.caption.10}\protected@file@percent }
\newlabel{fig:scaling_mixed_wiki_financial}{{4.2}{26}{Mixed Wiki+Financial Dataset: Scaling behavior shows normal pattern but with higher perplexity than pure financial mixture. The 15.1\% total improvement (0.6B to 4B) is smaller than pure financial (22.6\%), suggesting domain mixture creates competing optimization pressures that limit scaling benefits.\relax }{figure.caption.10}{}}
\newlabel{fig:scaling_mixed_wiki_financial@cref}{{[figure][2][4]4.2}{[1][25][]26}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Pure WikiText Baseline}{26}{subsection.4.2.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Mixed Wiki+Financial Dataset: Evaluation Across Multiple Datasets\relax }}{27}{table.caption.11}\protected@file@percent }
\newlabel{tab:mixed_wiki_financial_results}{{4.3}{27}{Mixed Wiki+Financial Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.11}{}}
\newlabel{tab:mixed_wiki_financial_results@cref}{{[table][3][4]4.3}{[1][25][]27}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Key Takeaway}{27}{subsection.4.2.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces WikiText Dataset: Severe reverse scaling phenomenon. The 1.7B model shows adjusted learning rate results (dashed line, squares) after fixing training collapse. The 4B model required 75\% LR reduction to stabilize. Clean, structured data amplifies learning rate sensitivity at larger scales.\relax }}{28}{figure.caption.12}\protected@file@percent }
\newlabel{fig:scaling_wikitext}{{4.3}{28}{WikiText Dataset: Severe reverse scaling phenomenon. The 1.7B model shows adjusted learning rate results (dashed line, squares) after fixing training collapse. The 4B model required 75\% LR reduction to stabilize. Clean, structured data amplifies learning rate sensitivity at larger scales.\relax }{figure.caption.12}{}}
\newlabel{fig:scaling_wikitext@cref}{{[figure][3][4]4.3}{[1][27][]28}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces WikiText Dataset: Impact of Learning Rate Adjustments\relax }}{28}{table.caption.13}\protected@file@percent }
\newlabel{tab:wikitext_lr_comparison}{{4.4}{28}{WikiText Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.13}{}}
\newlabel{tab:wikitext_lr_comparison@cref}{{[table][4][4]4.4}{[1][27][]28}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Comparison of all three mixture strategies across model sizes. Mixed Financial (blue) consistently outperforms Mixed Wiki+Financial (orange) and WikiText (green) on financial evaluation metrics. The divergence increases with model size, demonstrating that in-domain diversity scales better than general-domain quality.\relax }}{29}{figure.caption.14}\protected@file@percent }
\newlabel{fig:scaling_comparison_all}{{4.4}{29}{Comparison of all three mixture strategies across model sizes. Mixed Financial (blue) consistently outperforms Mixed Wiki+Financial (orange) and WikiText (green) on financial evaluation metrics. The divergence increases with model size, demonstrating that in-domain diversity scales better than general-domain quality.\relax }{figure.caption.14}{}}
\newlabel{fig:scaling_comparison_all@cref}{{[figure][4][4]4.4}{[1][29][]29}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Individual Dataset Analysis: Component Effects}{29}{section.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Large Datasets}{29}{subsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Financial News Articles Dataset: Excellent normal scaling with 21.7\% total improvement (0.6B to 4B). Large dataset size (197M tokens) provides sufficient diversity for stable training across all model sizes with minimal overtraining (2-3 epochs).\relax }}{31}{figure.caption.15}\protected@file@percent }
\newlabel{fig:scaling_news_articles}{{4.5}{31}{Financial News Articles Dataset: Excellent normal scaling with 21.7\% total improvement (0.6B to 4B). Large dataset size (197M tokens) provides sufficient diversity for stable training across all model sizes with minimal overtraining (2-3 epochs).\relax }{figure.caption.15}{}}
\newlabel{fig:scaling_news_articles@cref}{{[figure][5][4]4.5}{[1][30][]31}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces SEC Reports Dataset: Consistent normal scaling with 22.4\% total improvement. The 80M token corpus supports standalone pretraining with moderate overtraining (6-24 epochs). Strong transfer to similar long-form documents.\relax }}{31}{figure.caption.16}\protected@file@percent }
\newlabel{fig:scaling_sec_reports}{{4.6}{31}{SEC Reports Dataset: Consistent normal scaling with 22.4\% total improvement. The 80M token corpus supports standalone pretraining with moderate overtraining (6-24 epochs). Strong transfer to similar long-form documents.\relax }{figure.caption.16}{}}
\newlabel{fig:scaling_sec_reports@cref}{{[figure][6][4]4.6}{[1][30][]31}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Medium Datasets}{31}{subsection.4.3.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Financial News Dataset: Evaluation Across Multiple Datasets\relax }}{32}{table.caption.17}\protected@file@percent }
\newlabel{tab:news_articles_results}{{4.5}{32}{Financial News Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.17}{}}
\newlabel{tab:news_articles_results@cref}{{[table][5][4]4.5}{[1][30][]32}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces SEC Reports Dataset: Evaluation Across Multiple Datasets\relax }}{33}{table.caption.18}\protected@file@percent }
\newlabel{tab:sec_reports_results}{{4.6}{33}{SEC Reports Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.18}{}}
\newlabel{tab:sec_reports_results@cref}{{[table][6][4]4.6}{[1][30][]33}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Small Datasets}{33}{subsection.4.3.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces FinGPT Sentiment Dataset: Normal scaling with 22.1\% improvement despite moderate overtraining (12-30 epochs). Instruction-following format benefits from increased model capacity, showing strong transfer to similar task types.\relax }}{34}{figure.caption.19}\protected@file@percent }
\newlabel{fig:scaling_fingpt}{{4.7}{34}{FinGPT Sentiment Dataset: Normal scaling with 22.1\% improvement despite moderate overtraining (12-30 epochs). Instruction-following format benefits from increased model capacity, showing strong transfer to similar task types.\relax }{figure.caption.19}{}}
\newlabel{fig:scaling_fingpt@cref}{{[figure][7][4]4.7}{[1][33][]34}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Finance Alpaca Dataset: Consistent 21.8\% improvement across model sizes. Educational Q\&A format shows reliable scaling despite 13-25 epochs of training, but exhibits narrow task focus with 48\% cross-dataset variance.\relax }}{34}{figure.caption.20}\protected@file@percent }
\newlabel{fig:scaling_alpaca}{{4.8}{34}{Finance Alpaca Dataset: Consistent 21.8\% improvement across model sizes. Educational Q\&A format shows reliable scaling despite 13-25 epochs of training, but exhibits narrow task focus with 48\% cross-dataset variance.\relax }{figure.caption.20}{}}
\newlabel{fig:scaling_alpaca@cref}{{[figure][8][4]4.8}{[1][33][]34}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces FiQA Dataset: Strong normal scaling with 25.2\% total improvement. Despite small size (4M tokens), conversational Q\&A format produces stable training and excellent in-domain performance, though with high variance (52\%) on out-of-format tasks.\relax }}{35}{figure.caption.21}\protected@file@percent }
\newlabel{fig:scaling_fiqa}{{4.9}{35}{FiQA Dataset: Strong normal scaling with 25.2\% total improvement. Despite small size (4M tokens), conversational Q\&A format produces stable training and excellent in-domain performance, though with high variance (52\%) on out-of-format tasks.\relax }{figure.caption.21}{}}
\newlabel{fig:scaling_fiqa@cref}{{[figure][9][4]4.9}{[1][33][]35}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces FinGPT Sentiment Dataset: Evaluation Across Multiple Datasets\relax }}{36}{table.caption.22}\protected@file@percent }
\newlabel{tab:fingpt_results}{{4.7}{36}{FinGPT Sentiment Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.22}{}}
\newlabel{tab:fingpt_results@cref}{{[table][7][4]4.7}{[1][33][]36}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Financial QA 10K Dataset: Moderate reverse scaling resolved via learning rate adjustment. The 4B model (dashed line, squares) shows adjusted LR results with 10.3\% improvement, recovering expected scaling order. Extreme overtraining (67-100 epochs) causes 89\% cross-dataset variance.\relax }}{36}{figure.caption.25}\protected@file@percent }
\newlabel{fig:scaling_financial_qa}{{4.10}{36}{Financial QA 10K Dataset: Moderate reverse scaling resolved via learning rate adjustment. The 4B model (dashed line, squares) shows adjusted LR results with 10.3\% improvement, recovering expected scaling order. Extreme overtraining (67-100 epochs) causes 89\% cross-dataset variance.\relax }{figure.caption.25}{}}
\newlabel{fig:scaling_financial_qa@cref}{{[figure][10][4]4.10}{[1][36][]36}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Dataset Size vs Generalization}{36}{subsection.4.3.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Finance Alpaca Dataset: Evaluation Across Multiple Datasets\relax }}{37}{table.caption.23}\protected@file@percent }
\newlabel{tab:alpaca_results}{{4.8}{37}{Finance Alpaca Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.23}{}}
\newlabel{tab:alpaca_results@cref}{{[table][8][4]4.8}{[1][33][]37}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces FiQA Dataset: Evaluation Across Multiple Datasets\relax }}{38}{table.caption.24}\protected@file@percent }
\newlabel{tab:fiqa_results}{{4.9}{38}{FiQA Dataset: Evaluation Across Multiple Datasets\relax }{table.caption.24}{}}
\newlabel{tab:fiqa_results@cref}{{[table][9][4]4.9}{[1][33][]38}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Financial QA 10K Dataset: Impact of Learning Rate Adjustments\relax }}{38}{table.caption.27}\protected@file@percent }
\newlabel{tab:financial_qa_lr_comparison}{{4.10}{38}{Financial QA 10K Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.27}{}}
\newlabel{tab:financial_qa_lr_comparison@cref}{{[table][10][4]4.10}{[1][36][]38}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Training Dynamics and Scaling Behavior}{38}{section.4.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Twitter Financial Sentiment Dataset: Severe reverse scaling phenomenon. The 4B model (dashed line, squares) required 75\% LR reduction to recover performance, achieving 31.6\% improvement. Extremely small dataset (0.3M tokens, 150-249 epochs) creates brittle optimization landscape with 89\% variance.\relax }}{39}{figure.caption.26}\protected@file@percent }
\newlabel{fig:scaling_twitter}{{4.11}{39}{Twitter Financial Sentiment Dataset: Severe reverse scaling phenomenon. The 4B model (dashed line, squares) required 75\% LR reduction to recover performance, achieving 31.6\% improvement. Extremely small dataset (0.3M tokens, 150-249 epochs) creates brittle optimization landscape with 89\% variance.\relax }{figure.caption.26}{}}
\newlabel{fig:scaling_twitter@cref}{{[figure][11][4]4.11}{[1][36][]39}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Twitter Financial Dataset: Impact of Learning Rate Adjustments\relax }}{39}{table.caption.28}\protected@file@percent }
\newlabel{tab:twitter_lr_comparison}{{4.11}{39}{Twitter Financial Dataset: Impact of Learning Rate Adjustments\relax }{table.caption.28}{}}
\newlabel{tab:twitter_lr_comparison@cref}{{[table][11][4]4.11}{[1][36][]39}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Normal Scaling Pattern}{39}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Reverse Scaling Phenomenon}{40}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Learning Rate Sensitivity by Model Size}{42}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Fixing Reverse Scaling}{43}{subsection.4.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Model Stability Analysis}{45}{subsection.4.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Domain Transfer and Generalization Patterns}{46}{section.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Cross-Dataset Evaluation}{46}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Document Format and Task Type Effects}{48}{subsection.4.5.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Financial News Evaluation: Performance Across Training Datasets\relax }}{48}{table.caption.29}\protected@file@percent }
\newlabel{tab:cross_financial_news}{{4.12}{48}{Financial News Evaluation: Performance Across Training Datasets\relax }{table.caption.29}{}}
\newlabel{tab:cross_financial_news@cref}{{[table][12][4]4.12}{[1][48][]48}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces SEC Reports Evaluation: Performance Across Training Datasets\relax }}{49}{table.caption.30}\protected@file@percent }
\newlabel{tab:cross_financial_repor}{{4.13}{49}{SEC Reports Evaluation: Performance Across Training Datasets\relax }{table.caption.30}{}}
\newlabel{tab:cross_financial_repor@cref}{{[table][13][4]4.13}{[1][48][]49}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Alpaca Evaluation: Performance Across Training Datasets\relax }}{50}{table.caption.31}\protected@file@percent }
\newlabel{tab:cross_alpaca}{{4.14}{50}{Alpaca Evaluation: Performance Across Training Datasets\relax }{table.caption.31}{}}
\newlabel{tab:cross_alpaca@cref}{{[table][14][4]4.14}{[1][49][]50}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.15}{\ignorespaces FinGPT Evaluation: Performance Across Training Datasets\relax }}{51}{table.caption.32}\protected@file@percent }
\newlabel{tab:cross_fingpt}{{4.15}{51}{FinGPT Evaluation: Performance Across Training Datasets\relax }{table.caption.32}{}}
\newlabel{tab:cross_fingpt@cref}{{[table][15][4]4.15}{[1][49][]51}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Variance Comparison}{51}{subsection.4.5.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.16}{\ignorespaces FiQA Evaluation: Performance Across Training Datasets\relax }}{52}{table.caption.33}\protected@file@percent }
\newlabel{tab:cross_fiqa}{{4.16}{52}{FiQA Evaluation: Performance Across Training Datasets\relax }{table.caption.33}{}}
\newlabel{tab:cross_fiqa@cref}{{[table][16][4]4.16}{[1][49][]52}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.17}{\ignorespaces Twitter Financial Evaluation: Performance Across Training Datasets\relax }}{53}{table.caption.34}\protected@file@percent }
\newlabel{tab:cross_twitter}{{4.17}{53}{Twitter Financial Evaluation: Performance Across Training Datasets\relax }{table.caption.34}{}}
\newlabel{tab:cross_twitter@cref}{{[table][17][4]4.17}{[1][50][]53}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.18}{\ignorespaces Financial QA Evaluation: Performance Across Training Datasets\relax }}{54}{table.caption.35}\protected@file@percent }
\newlabel{tab:cross_financial_qa}{{4.18}{54}{Financial QA Evaluation: Performance Across Training Datasets\relax }{table.caption.35}{}}
\newlabel{tab:cross_financial_qa@cref}{{[table][18][4]4.18}{[1][53][]54}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Domain-Specific vs General Knowledge Transfer}{54}{subsection.4.5.4}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.19}{\ignorespaces WikiText Evaluation: Performance Across Training Datasets\relax }}{56}{table.caption.36}\protected@file@percent }
\newlabel{tab:cross_wikitext}{{4.19}{56}{WikiText Evaluation: Performance Across Training Datasets\relax }{table.caption.36}{}}
\newlabel{tab:cross_wikitext@cref}{{[table][19][4]4.19}{[1][56][]56}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Summary and Key Results}{57}{section.4.6}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.20}{\ignorespaces Best configurations by application. *SEC's 18\% CV is in-domain only; cross-dataset CV is 32\%.\relax }}{58}{table.caption.37}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{60}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Key Empirical Findings}{60}{section.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Interpretation of Data Interaction Effects}{62}{section.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Why WikiText Underperforms on Financial Tasks}{62}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Benefits of In-Domain Diversity}{63}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Domain Interference Patterns}{65}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Scale-Dependent Training Dynamics}{66}{subsection.5.2.4}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\abx@aux@page{11}{67}
\abx@aux@page{12}{67}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Practical Guidelines for Financial LM Pretraining}{67}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Data Mixture Strategies by Use Case}{67}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Model Size Selection}{68}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Learning Rate Guidelines by Model Size}{69}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Token Budget Allocation}{70}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Limitations and Threats to Validity}{70}{section.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{72}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}Summary of Contributions}{72}{section.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Data Mixture Guidelines for Financial NLP}{72}{subsection.6.1.1}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Learning Rate Scaling Laws for Decoder-Only Transformers}{73}{subsection.6.1.2}\protected@file@percent }
\abx@aux@page{13}{73}
\abx@aux@page{14}{73}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Dataset Size Effects and Generalization}{73}{subsection.6.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Domain Transfer and Format Effects}{74}{subsection.6.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.5}Model Size Selection for Resource-Constrained Settings}{75}{subsection.6.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.6}Open-Source Reproducible Pipeline}{75}{subsection.6.1.6}\protected@file@percent }
\abx@aux@cite{kaplan2020scaling}
\abx@aux@segm{0}{0}{kaplan2020scaling}
\abx@aux@cite{hoffmann2022training}
\abx@aux@segm{0}{0}{hoffmann2022training}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}Implications for Practice and Research}{76}{section.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}For Practitioners: Actionable Deployment Guidelines}{76}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}For Researchers: Open Questions and Methodological Lessons}{76}{subsection.6.2.2}\protected@file@percent }
\abx@aux@page{15}{76}
\abx@aux@page{16}{76}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}For Industry: Privacy-Preserving Financial AI}{77}{subsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future Research Directions}{78}{section.6.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Scaling to Larger Models and Architectures}{78}{subsection.6.3.1}\protected@file@percent }
\abx@aux@cite{doremi2023}
\abx@aux@segm{0}{0}{doremi2023}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Advanced Mixture Optimization}{79}{subsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Comprehensive Downstream Evaluation}{79}{subsection.6.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Multi-Stage Pretraining Strategies}{80}{subsection.6.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}Theoretical Understanding of Learning Rate Scaling}{80}{subsection.6.3.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.4}Closing Remarks}{81}{section.6.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Appendices}{}{section*.38}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Experimental Details}{84}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chp:experimental_details}{{A}{84}{Experimental Details}{appendix.A}{}}
\newlabel{chp:experimental_details@cref}{{[appendix][1][2147483647]A}{[1][84][]84}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.1}Complete Hyperparameter Tables}{84}{section.A.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.2}Additional Results Tables}{84}{section.A.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A.3}Dataset Preprocessing Details}{84}{section.A.3}\protected@file@percent }
\abx@aux@page{17}{85}
\abx@aux@page{18}{85}
\abx@aux@page{19}{85}
\abx@aux@page{20}{85}
\abx@aux@page{21}{85}
\abx@aux@page{22}{85}
\abx@aux@page{23}{85}
\abx@aux@read@bbl@mdfivesum{55A51D7A69101CFBDBC3B10BB8907F8E}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{araci2019finbert}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{brown2020language}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{gururangan2020don}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hoffmann2022training}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kaplan2020scaling}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{radford2019language}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{touvron2023llama}{nyt/global//global/global}
\gdef \@abspage@last{98}
