% Cross-Dataset Comparison: Financial QA as Evaluation Dataset
% Shows which training dataset performs best on Financial QA
% Bold values indicate best performance for each model size

\begin{table}[h]
\centering
\caption{Financial QA Evaluation: Performance Across Training Datasets}
\label{tab:cross_financial_qa}
\begin{tabular}{l|ccc|ccc}
\hline
\textbf{Training Dataset} & \multicolumn{3}{c|}{\textbf{Cross-Entropy Loss}} & \multicolumn{3}{c}{\textbf{Perplexity}} \\n\cline{2-4} \cline{5-7}
  & \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} & \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} \\
Alpaca (2e-5) & 4.77 & 2.95 & 2.15 & 117.40 & 19.11 & 8.56  \
 Financial QA (2e-5) & \textbf{2.12} & \textbf{2.01} & 2.12 & \textbf{8.29} & \textbf{7.44} & 8.29  \
 Financial QA (1.7B: 1e-5, 4B: 5e-6) & \textbf{2.12} & 2.12 & 2.01 & \textbf{8.29} & 8.29 & 7.43  \
 FinGPT (2e-5) & 3.66 & 2.38 & \textbf{1.83} & 38.96 & 10.85 & \textbf{6.24}  \
 FiQA (2e-5) & 4.64 & 2.60 & 1.84 & 103.40 & 13.53 & 6.32  \
 Mixed Financial (2e-5) & 5.21 & 3.75 & 3.23 & 183.72 & 42.30 & 25.14  \
 Mixed Wiki+Financial (2e-5) & 4.58 & 3.87 & 3.46 & 97.49 & 47.94 & 31.76  \
 Financial News (2e-5) & 5.11 & 3.90 & 3.66 & 166.10 & 49.53 & 38.90  \
 SEC Reports (2e-5) & 3.90 & 3.08 & 2.86 & 49.30 & 21.77 & 17.39  \
 Twitter Financial (2e-5) & 2.46 & 2.32 & 2.83 & 11.76 & 10.15 & 16.98  \
 Twitter Financial (1.7B: 1e-5, 4B: 5e-6) & 2.46 & 2.16 & 2.43 & 11.76 & 8.69 & 11.39  \
 WikiText (2e-5) & 3.40 & 10.67 & 3.37 & 29.90 & $\infty$ & 29.08  \
 WikiText (1.7B: 5e-6, 4B: 3e-6) & 3.40 & 4.07 & 3.87 & 29.90 & 58.33 & 47.98  \
\hline
\end{tabular}
\end{table}

