% Cross-Dataset Comparison: Financial News as Evaluation Dataset
% Shows which training dataset performs best on Financial News
% Bold values indicate best performance for each model size

\begin{table}[h]
\centering
\caption{Financial News Evaluation: Performance Across Training Datasets}
\label{tab:cross_financial_news}
\resizebox{\textwidth}{!}{
\begin{tabular}{l|ccc|ccc}
\toprule
\multirow{2}{*}{\textbf{Training Dataset}} &
\multicolumn{3}{c|}{\textbf{Cross-Entropy Loss}} &
\multicolumn{3}{c}{\textbf{Perplexity}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
& \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} & \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} \\
\midrule
Alpaca (2e-5) & 3.92 & 2.71 & 2.15 & 50.40 & 15.05 & 8.58 \\
Financial QA (2e-5) & \textbf{2.36} & \textbf{2.17} & 2.13 & \textbf{10.60} & \textbf{8.78} & 8.41 \\
Financial QA (1.7B: 1e-5, 4B: 5e-6) & \textbf{2.36} & 2.23 & 2.04 & \textbf{10.60} & 9.25 & 7.71 \\
FinGPT (2e-5) & 3.36 & 2.45 & 2.07 & 28.72 & 11.58 & 7.92 \\
FiQA (2e-5) & 3.90 & 2.54 & \textbf{2.01} & 49.22 & 12.74 & \textbf{7.43} \\
Mixed Financial (2e-5) & 4.03 & 3.05 & 2.63 & 56.35 & 21.19 & 13.84 \\
Mixed Wiki+Financial (2e-5) & 3.65 & 3.13 & 2.77 & 38.68 & 22.79 & 15.91 \\
Financial News (2e-5) & 3.96 & 3.13 & 2.86 & 52.25 & 22.91 & 17.47 \\
SEC Reports (2e-5) & 3.71 & 3.08 & 2.81 & 40.85 & 21.65 & 16.67 \\
Twitter Financial (2e-5) & 3.17 & 2.80 & 2.87 & 23.77 & 16.48 & 17.67 \\
Twitter Financial (1.7B: 1e-5, 4B: 5e-6) & 3.17 & 2.65 & 2.54 & 23.77 & 14.10 & 12.68 \\
WikiText (2e-5) & 2.62 & 2.93 & 3.37 & 13.70 & 18.78 & 29.19 \\
WikiText (1.7B: 5e-6, 4B: 3e-6) & 2.62 & 3.52 & 3.27 & 13.70 & 33.66 & 26.44 \\
\bottomrule
\end{tabular}
}
\end{table}

