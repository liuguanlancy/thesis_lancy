% Financial QA 10K Dataset: Evaluation Results
% Training: Financial QA 10K (virattt/financial-qa-10K, 3.5M tokens)
% All models trained with LR=2e-5

\begin{table}[h]
\centering
\caption{Financial QA 10K Dataset: Evaluation Across Multiple Datasets}
\label{tab:financial_qa_results}
\begin{tabular}{l|ccc|ccc}
\hline
\textbf{Eval Dataset} & \multicolumn{3}{c|}{\textbf{Cross-Entropy Loss}} & \multicolumn{3}{c}{\textbf{Perplexity}} \\n\cline{2-4} \cline{5-7}
  & \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} & \textbf{0.6B} & \textbf{1.7B} & \textbf{4B} \\
Alpaca & 2.38 & \textbf{2.23} & 2.29 & 10.82 & \textbf{9.31} & 9.91 \
 Financial News & 2.36 & 2.17 & \textbf{2.13} & 10.60 & \textbf{8.78} & \textbf{8.41} \
 Financial Repor & 2.11 & \textbf{2.00} & 2.11 & 8.21 & \textbf{7.40} & 8.25 \
 Fingpt & 2.31 & \textbf{2.15} & 2.23 & 10.04 & \textbf{8.62} & 9.34 \
 Fiqa & 2.40 & \textbf{2.25} & 2.31 & 11.02 & \textbf{9.45} & 10.05 \
 Twitter & 2.21 & \textbf{2.10} & 2.20 & 9.14 & \textbf{8.18} & 8.99 \
 Wikitext & 2.24 & \textbf{2.11} & 2.19 & 9.41 & \textbf{8.23} & 8.89 \
\hline
\end{tabular}
\end{table}

